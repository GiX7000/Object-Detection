{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RetinaNet_on_PascalVoc_Subset.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiX7000/object-detection/blob/main/RetinaNet_on_PascalVoc_Subset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N8ud1eTZhk-"
      },
      "source": [
        "# Implementation of RetinaNet on a subset of PascalVoc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZLoorG43mU1"
      },
      "source": [
        "Use of [Fizyr's](https://github.com/fizyr/keras-retinanet) official implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PdMj4Tn3tgN"
      },
      "source": [
        "# get retinanet and install the appropriate environment\n",
        "\n",
        "!git clone https://github.com/fizyr/keras-retinanet.git\n",
        "\n",
        "%cd keras-retinanet/\n",
        "\n",
        "!pip install .\n",
        "\n",
        "!python setup.py build_ext --inplace\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import urllib\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "import csv\n",
        "import pandas\n",
        "from google.colab import drive\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfSozUXzbNdr"
      },
      "source": [
        "# mount drive to get the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bX4X-W2jG917"
      },
      "source": [
        "Images_set3b is subset of Pascal Voc dataset, which is comprised of a specific number of specific classes. More details at PascalVoc_Subset.ipynb."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVaI1KPjKf8N"
      },
      "source": [
        "# copy dataset to Colab VM\n",
        "%cd /content/drive/MyDrive/\n",
        "!cp -r images_set3b /content/keras-retinanet/images/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lol2uz-HWwO"
      },
      "source": [
        "# create annotations.csv and classes.csv files\n",
        "%cd /content/keras-retinanet/images/images_set3b\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# annotation csvs\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member.find(\"bndbox\").find('xmin').text),\n",
        "                     int(member.find(\"bndbox\").find('ymin').text),\n",
        "                     int(member.find(\"bndbox\").find('xmax').text),\n",
        "                     int(member.find(\"bndbox\").find('ymax').text))\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "\n",
        "\n",
        "def main():\n",
        "    datasets = ['train', 'test']\n",
        "    for ds in datasets:\n",
        "      image_path = os.path.join(os.getcwd(), ds)\n",
        "      xml_df = xml_to_csv(image_path)\n",
        "      xml_df.to_csv(ds + '_annotations.csv', index=None)\n",
        "print('Successfully converted xml to csv.')\n",
        "\n",
        "main()\n",
        "\n",
        "# classes csv\n",
        "classes = [['cow',0], ['horse',1], ['sheep',2], ['person',3]]\n",
        "\n",
        "with open('classes.csv', 'w', newline='') as f:\n",
        "  writer = csv.writer(f)\n",
        "  #writer.writerow([\"class_name\", \"class_id\"])\n",
        "  writer.writerows(classes)\n",
        "print('Successfully created classes.csv file')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFHK2gP8eBq6"
      },
      "source": [
        "# transform csvs to retinanet csv format. More info about retina's csv format here: https://github.com/fizyr/keras-retinanet\n",
        "\n",
        "csv_files = ['train_annotations.csv', 'test_annotations.csv']\n",
        "\n",
        "for csv_file in csv_files:\n",
        "  f = pd.read_csv(csv_file)\n",
        "  # keep filename, xmin, ymin, xmax, ymax, class columns\n",
        "  keep_col = ['filename', 'xmin', 'ymin', 'xmax', 'ymax', 'class']\n",
        "  tmp = f[keep_col]\n",
        "  # skip the header row from top\n",
        "  tmp.columns = tmp.iloc[0]\n",
        "  final = tmp[1:]\n",
        "  final.to_csv('retinanet_'+csv_file, index=False)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjK37EtWlgZM"
      },
      "source": [
        "# keep rows with objects that belong in our classes_list\n",
        "\n",
        "retinanet_csv_files = ['retinanet_train_annotations.csv', 'retinanet_test_annotations.csv']\n",
        "classes_list = ['cow', 'horse', 'sheep', 'person']\n",
        "\n",
        "with open('retinanet_train_annotations.csv', 'r') as inp, open('final_retinanet_train_annotations.csv', 'w') as out:\n",
        "    writer = csv.writer(out)\n",
        "    for row in csv.reader(inp):\n",
        "        if row[5] in classes_list:\n",
        "            writer.writerow(row)\n",
        "\n",
        "with open('retinanet_test_annotations.csv', 'r') as inp, open('final_retinanet_test_annotations.csv', 'w') as out:\n",
        "    writer = csv.writer(out)\n",
        "    for row in csv.reader(inp):\n",
        "        if row[5] in classes_list:\n",
        "            writer.writerow(row)\n",
        "\n",
        "# move csvs in train/test images dirs\n",
        "!mv final_retinanet_train_annotations.csv /content/keras-retinanet/images/images_set3b/train\n",
        "!mv final_retinanet_test_annotations.csv /content/keras-retinanet/images/images_set3b/test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGtn3JW6Mig8"
      },
      "source": [
        "# Training Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C05G5pLNbC2j"
      },
      "source": [
        "# download the pre-trained model\n",
        "import urllib.request\n",
        "\n",
        "PRETRAINED_MODEL = '/content/keras-retinanet/snapshots/_pretrained_model.h5'\n",
        "\n",
        "URL_MODEL = 'https://github.com/fizyr/keras-retinanet/releases/download/0.5.1/resnet50_coco_best_v2.1.0.h5'\n",
        "urllib.request.urlretrieve(URL_MODEL, PRETRAINED_MODEL)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7hWNG7i_dcH"
      },
      "source": [
        "# total training time\n",
        "!pip install ipython-autotime\n",
        "\n",
        "%load_ext autotime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpoAcXzoiDHv"
      },
      "source": [
        "%cd /content/keras-retinanet/images/images_set3b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjwHruzMiqZH"
      },
      "source": [
        "# define steps_per_epoch = len(X_train)//batch_size\n",
        "batch_size = 6\n",
        "print( len(os.listdir('/content/keras-retinanet/images/images_set3b/train'))/2  // batch_size) # remember that train folder contains images and their corespnding xmls, that's why there's a division with 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY1Mkxj6bY14"
      },
      "source": [
        "# start training\n",
        "%cd /content/keras-retinanet/keras_retinanet/bin\n",
        "\n",
        "!python train.py --freeze-backbone --random-transform --weights {PRETRAINED_MODEL} --batch-size 6 --steps 29 --epochs 5 csv /content/keras-retinanet/images/images_set3b/train/final_retinanet_train_annotations.csv /content/keras-retinanet/images/images_set3b/classes.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1ujgq5pntZ5"
      },
      "source": [
        "# convert training model to inference model\n",
        "!python convert_model.py /content/keras-retinanet/keras_retinanet/bin/snapshots/resnet50_csv_05.h5 /content/keras-retinanet/keras_retinanet/bin/snapshots/my_resnet50_csv_05.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT_ipsl_bYys"
      },
      "source": [
        "# evaluation\n",
        "!python evaluate.py --save-path /content/keras-retinanet/keras_retinanet/bin/snapshots csv /content/keras-retinanet/images/images_set3b/test/final_retinanet_test_annotations.csv /content/keras-retinanet/images/images_set3b/classes.csv /content/keras-retinanet/keras_retinanet/bin/snapshots/my_resnet50_csv_05.h5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blgREOLxbYv8"
      },
      "source": [
        "# start Tensorboard\n",
        "# some modifications needed to original python scripts, , as well as to print mAR and f1 score above!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvBvKP5SbYr0"
      },
      "source": [
        "# export the trained model to drive\n",
        "COLAB_MODEL = '/content/keras-retinanet/keras_retinanet/bin/snapshots/my_resnet50_csv_05.h5'\n",
        "DRIVE_DIR = '/content/drive/MyDrive/'\n",
        "shutil.copy(COLAB_MODEL, DRIVE_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYyfa8yniJiW"
      },
      "source": [
        "# test the model\n",
        "THRES_SCORE = 0.6\n",
        "\n",
        "# show images inline\n",
        "%matplotlib inline\n",
        "\n",
        "# automatically reload modules when they have changed\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# import keras\n",
        "import keras\n",
        "\n",
        "# import keras_retinanet\n",
        "from keras_retinanet import models\n",
        "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
        "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
        "from keras_retinanet.utils.colors import label_color\n",
        "\n",
        "# import miscellaneous modules\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# set tf backend to allow memory to grow, instead of claiming everything\n",
        "import tensorflow as tf\n",
        "\n",
        "def get_session():\n",
        "    config = tf.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True\n",
        "    return tf.Session(config=config)\n",
        "\n",
        "# set the modified tf session as backend in keras\n",
        "tf.config.list_physical_devices('GPU') \n",
        "#keras.backend.tensorflow_backend.set_session(get_session())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkewNh9UiOs1"
      },
      "source": [
        "# load the model from last checkpoint\n",
        "model_path = '/content/keras-retinanet/keras_retinanet/bin/snapshots/resnet50_csv_05.h5'\n",
        "print(model_path)\n",
        "\n",
        "# load retinanet model\n",
        "model = models.load_model(model_path, backbone_name='resnet50')\n",
        "model = models.convert_model(model)\n",
        "\n",
        "# load label to names mapping for visualization purposes\n",
        "labels_to_names = pandas.read_csv('/content/keras-retinanet/images/images_set3b/classes.csv',header=None).T.loc[0].to_dict()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWSHqP1KTHxQ"
      },
      "source": [
        "def img_inference(img_path):\n",
        "  image = read_image_bgr(img_infer)\n",
        "\n",
        "  # copy to draw on\n",
        "  draw = image.copy()\n",
        "  draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # preprocess image for network\n",
        "  image = preprocess_image(image)\n",
        "  image, scale = resize_image(image)\n",
        "\n",
        "  # process image\n",
        "  start = time.time()\n",
        "  boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
        "  print(\"processing time: \", time.time() - start)\n",
        "\n",
        "  # correct for image scale\n",
        "  boxes /= scale\n",
        "\n",
        "  # visualize detections\n",
        "  for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
        "      # scores are sorted so we can break\n",
        "      if score < THRES_SCORE:\n",
        "          break\n",
        "\n",
        "      color = label_color(label)\n",
        "\n",
        "      b = box.astype(int)\n",
        "      draw_box(draw, b, color=color)\n",
        "\n",
        "      caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
        "      print(caption)\n",
        "      draw_caption(draw, b, caption)\n",
        "\n",
        "  plt.figure(figsize=(20, 20))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(draw)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_AoWG4lHFME"
      },
      "source": [
        "# upload an image for testing\n",
        "uploaded = files.upload()\n",
        "img_infer = list(uploaded)[0]\n",
        "\n",
        "print('Running inference on: ' + img_infer)\n",
        "img_inference(img_infer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhHD7Ramz9bk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}