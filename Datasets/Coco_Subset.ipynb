{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Coco_Subset.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPoRH4enAI6DqGdfN9C/iy7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"l7KVeOcWEl4J"},"source":["Creation of a subset of Coco dataset\n","\n"]},{"cell_type":"code","metadata":{"id":"nVAW7PFqrP15","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616608428309,"user_tz":-120,"elapsed":10938,"user":{"displayName":"G X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPM3nBcSIAiq4wgSkRDneXZblaI339eFJPGU8gtg=s64","userId":"07430575892639430364"}},"outputId":"04b864ed-292d-47d5-d573-ed20af486736"},"source":["# download coco's annotations trainval2017 and by using coco API, create a subset\n","\n","!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n","!unzip annotations_trainval2017.zip\n","!rm -rf annotations_trainval2017.zip\n","\n","# keep only instances_train/val.json \n","%cd /content/annotations/\n","!rm captions_train2017.json\n","!rm captions_val2017.json\n","!rm person_keypoints_train2017.json\n","!rm person_keypoints_val2017.json"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2021-03-24 17:53:46--  http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n","Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.228.104\n","Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.228.104|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 252907541 (241M) [application/zip]\n","Saving to: ‘annotations_trainval2017.zip’\n","\n","annotations_trainva 100%[===================>] 241.19M  98.2MB/s    in 2.5s    \n","\n","2021-03-24 17:53:48 (98.2 MB/s) - ‘annotations_trainval2017.zip’ saved [252907541/252907541]\n","\n","Archive:  annotations_trainval2017.zip\n","  inflating: annotations/instances_train2017.json  \n","  inflating: annotations/instances_val2017.json  \n","  inflating: annotations/captions_train2017.json  \n","  inflating: annotations/captions_val2017.json  \n","  inflating: annotations/person_keypoints_train2017.json  \n","  inflating: annotations/person_keypoints_val2017.json  \n","/content/annotations\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m5yBUNY3GsrV","executionInfo":{"status":"ok","timestamp":1616608445200,"user_tz":-120,"elapsed":27820,"user":{"displayName":"G X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPM3nBcSIAiq4wgSkRDneXZblaI339eFJPGU8gtg=s64","userId":"07430575892639430364"}},"outputId":"4b61d996-a1b7-48ed-baab-53fd0b91bbbf"},"source":["# use of coco API\n","\n","from pycocotools.coco import COCO\n","import requests\n","import random\n","\n","# take 45 images with their annotations for each of 4 classes for training and another 10 for testing, respectively\n","classes = ['person', 'horse', 'cow', 'sheep']\n","\n","imagesTrain = []\n","imagesVal = []\n","\n","#unique_imagesTrain = []\n","#unique_imagesVal = []\n","\n","subimagesTrain = []\n","subimagesVal = []\n","\n","cocoTrain = COCO('/content/annotations/instances_train2017.json')\n","cocoVal = COCO('/content/annotations/instances_val2017.json')\n","\n","for className in classes:\n","\n","  # images for training\n","  catIdsTrain = cocoTrain.getCatIds(catNms=className)\n","  imgIdsTrain = cocoTrain.getImgIds(catIds=catIdsTrain)\n","  imagesTrain = cocoTrain.loadImgs(imgIdsTrain)\n","\n","  # filter out the repeated images    \n","  #for k in range(len(imagesTrain)):\n","  #  if imagesTrain[k] not in unique_imagesTrain:\n","  #    unique_imagesTrain.append(imagesTrain[k])\n","\n","  # take 45 of them randomly\n","  subimagesTrain += random.sample(imagesTrain, 45)\n","\n","  # images for testing\n","  catIdsVal = cocoVal.getCatIds(catNms=className)\n","  imgIdsVal = cocoVal.getImgIds(catIds=catIdsVal)\n","  imagesVal = cocoVal.loadImgs(imgIdsVal)\n","\n","  # filter out the repeated images\n","  #for l in range(len(imagesVal)):\n","  #  if imagesVal[l] not in unique_imagesVal:\n","  #    unique_imagesVal.append(imagesVal[l])\n","\n","  # take 10 of them randomly\n","  subimagesVal += random.sample(imagesVal, 10)\n","\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["loading annotations into memory...\n","Done (t=15.32s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=0.50s)\n","creating index...\n","index created!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cVOKCId1GsoT","executionInfo":{"status":"ok","timestamp":1616608467556,"user_tz":-120,"elapsed":50172,"user":{"displayName":"G X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPM3nBcSIAiq4wgSkRDneXZblaI339eFJPGU8gtg=s64","userId":"07430575892639430364"}}},"source":["# save images to dir\n","!mkdir train_images\n","!mkdir test_images\n","\n","for im in subimagesTrain:\n","  #print(\"im: \", im)\n","  img_data = requests.get(im['coco_url']).content\n","  with open('train_images/' + im['file_name'], 'wb') as handler:\n","    handler.write(img_data)\n","\n","for im2 in subimagesVal:\n","  #print(\"im: \", im)\n","  img_data2 = requests.get(im2['coco_url']).content\n","  with open('test_images/' + im2['file_name'], 'wb') as handler:\n","    handler.write(img_data2)\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-b1pTX6hMM2N","executionInfo":{"status":"ok","timestamp":1616608467558,"user_tz":-120,"elapsed":50170,"user":{"displayName":"G X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPM3nBcSIAiq4wgSkRDneXZblaI339eFJPGU8gtg=s64","userId":"07430575892639430364"}},"outputId":"974db9b3-0394-42ec-9b99-65774ef23118"},"source":["# check the lengths of dirs\n","import os\n","\n","print(len(os.listdir('/content/annotations/train_images')))\n","print(len(os.listdir('/content/annotations/test_images')))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["180\n","39\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"voP39tHlGslb","executionInfo":{"status":"ok","timestamp":1616608467560,"user_tz":-120,"elapsed":50167,"user":{"displayName":"G X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPM3nBcSIAiq4wgSkRDneXZblaI339eFJPGU8gtg=s64","userId":"07430575892639430364"}}},"source":["# keep annotations of the above train/test images at .csv and .json data files\n","\n","# csv\n","\n","import csv\n","header = ['filename', 'x', 'y', 'width', 'height', 'category_id' ]\n","\n","with open('train_annotations'  + '.csv', mode='w', newline='') as annot:\n","  annot_writer = csv.writer(annot)\n","  annot_writer.writerow(header)\n","  for im in subimagesTrain:    \n","    annIdsTrain = cocoTrain.getAnnIds(imgIds=im['id'])\n","    annsTrain = cocoTrain.loadAnns(annIdsTrain)\n","    for i in range(len(annsTrain)):\n","      #annot_writer.writerow([im['coco_url'], anns[i]['bbox'][0], anns[i]['bbox'][1], anns[i]['bbox'][0] + anns[i]['bbox'][2], anns[i]['bbox'][1] + anns[i]['bbox'][3], anns[i].get('category_id')])\n","      annot_writer.writerow([im['file_name'], int(round(annsTrain[i]['bbox'][0])), int(round(annsTrain[i]['bbox'][1])), int(round(annsTrain[i]['bbox'][0] + annsTrain[i]['bbox'][2])), int(round(annsTrain[i]['bbox'][1] + annsTrain[i]['bbox'][3])), annsTrain[i].get('category_id')])\n","annot.close()\n","\n","with open('test_annotations'  + '.csv', mode='w', newline='') as annot2:\n","  annot_writer2 = csv.writer(annot2)\n","  annot_writer2.writerow(header)\n","  for im2 in subimagesVal:    \n","    annIdsVal = cocoVal.getAnnIds(imgIds=im2['id'])\n","    annsVal = cocoVal.loadAnns(annIdsVal)\n","    for i2 in range(len(annsVal)):\n","      #annot_writer.writerow([im['coco_url'], anns[i]['bbox'][0], anns[i]['bbox'][1], anns[i]['bbox'][0] + anns[i]['bbox'][2], anns[i]['bbox'][1] + anns[i]['bbox'][3], anns[i2].get('category_id')])\n","      annot_writer2.writerow([im2['file_name'], int(round(annsVal[i2]['bbox'][0])), int(round(annsVal[i2]['bbox'][1])), int(round(annsVal[i2]['bbox'][0] + annsVal[i2]['bbox'][2])), int(round(annsVal[i2]['bbox'][1] + annsVal[i2]['bbox'][3])), annsVal[i2].get('category_id')])\n","annot2.close()\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"AbFIguQaXXo_","executionInfo":{"status":"ok","timestamp":1616608467561,"user_tz":-120,"elapsed":50165,"user":{"displayName":"G X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPM3nBcSIAiq4wgSkRDneXZblaI339eFJPGU8gtg=s64","userId":"07430575892639430364"}}},"source":["# json\n","import json \n","\n","def csv_to_json(csvFilePath, jsonFilePath):\n","    jsonArray = []\n","      \n","    #read csv file\n","    with open(csvFilePath, encoding='utf-8') as csvf: \n","        #load csv file data using csv library's dictionary reader\n","        csvReader = csv.DictReader(csvf) \n","\n","        #convert each csv row into python dict\n","        for row in csvReader: \n","            #add this python dict to json array\n","            jsonArray.append(row)\n","  \n","    #convert python jsonArray to JSON String and write to file\n","    with open(jsonFilePath, 'w', encoding='utf-8') as jsonf: \n","        jsonString = json.dumps(jsonArray, indent=4)\n","        jsonf.write(jsonString)\n","\n","csvFilePathTrain = r'/content/annotations/train_annotations.csv'\n","jsonFilePathTrain = r'train_annotations.json'\n","csv_to_json(csvFilePathTrain, jsonFilePathTrain)\n","\n","csvFilePathVal = r'/content/annotations/test_annotations.csv'\n","jsonFilePathVal = r'test_annotations.json'\n","csv_to_json(csvFilePathVal, jsonFilePathVal)\n"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"w7DimPbKGsfU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1616608467563,"user_tz":-120,"elapsed":50163,"user":{"displayName":"G X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPM3nBcSIAiq4wgSkRDneXZblaI339eFJPGU8gtg=s64","userId":"07430575892639430364"}},"outputId":"8c3fd4aa-af31-4032-f12c-b2135e77213c"},"source":["# all in one file\n","%cd /content/\n","os.rename('annotations', 'images_set2')\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9ULS2Sy2JEYr"},"source":["images_set2 is now a subset of Coco dataset, combrised of 4 classes with 45 images each for training and 10 for testing."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"z_Bt9buxbC8o","executionInfo":{"status":"ok","timestamp":1616609969258,"user_tz":-120,"elapsed":41113,"user":{"displayName":"G X","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPM3nBcSIAiq4wgSkRDneXZblaI339eFJPGU8gtg=s64","userId":"07430575892639430364"}},"outputId":"b5101525-1451-4f41-88db-48fc2131b647"},"source":["import shutil\n","shutil.make_archive('images_set2', 'zip', '/content/')"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/images_set2.zip'"]},"metadata":{"tags":[]},"execution_count":16}]}]}